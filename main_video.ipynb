{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install opencv-python\n",
    "# !pip install opencv-contrib-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from cv2 import dnn_superres\n",
    "import moviepy\n",
    "import moviepy.editor\n",
    "import os\n",
    "\n",
    "file_name = 'low_res_2'\n",
    "ext = 'mp4'\n",
    "scale = 4\n",
    "input_video = f'./input/videos/{file_name}.{ext}'\n",
    "output_root_path = f'./output/videos/{file_name}'\n",
    "os.mkdir(output_root_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<moviepy.audio.io.AudioFileClip.AudioFileClip at 0x7fbf38275640>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from moviepy.editor import AudioFileClip\n",
    "\n",
    "video = moviepy.editor.VideoFileClip(input_video)\n",
    "audio = video.audio\n",
    "audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tqdm.auto import tqdm\n",
    "\n",
    "# # bicubic upsampling\n",
    "\n",
    "# vs = cv2.VideoCapture(input_video)\n",
    "# success, frame = vs.read()\n",
    "# input_width = frame.shape[1] # 640\n",
    "# input_height = frame.shape[0] # 352\n",
    "# frame_count = 0\n",
    "# total_frames = vs.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "# frame_rate = vs.get(cv2.CAP_PROP_FPS)\n",
    "# print(f'input res: {frame.shape}, total frames={total_frames}, frame rate={frame_rate}')\n",
    "# first_part = output_video.split('.')[1]\n",
    "# second_part = output_video.split('.')[2]\n",
    "# output_path = first_part+'_'+'cubicx_'+scale+'.'+second_part\n",
    "# out = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'mp4v'),\n",
    "#                          frame_rate, (scale*input_width, scale*input_height))\n",
    "\n",
    "# with tqdm(total=total_frames) as pbar:\n",
    "#     while success:\n",
    "#         upsampled_frame = cv2.resize(frame, None, fx=scale, fy=scale, interpolation=cv2.INTER_CUBIC)\n",
    "#         out.write(upsampled_frame)\n",
    "\n",
    "#         frame_count += 1\n",
    "#         pbar.update(1)\n",
    "#         pbar.set_description(f'frame no: {frame_count}')\n",
    "#         success, frame = vs.read()\n",
    "#     pbar.close()\n",
    "\n",
    "# vs.release()\n",
    "# out.release()\n",
    "# print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import os\n",
    "# from tqdm.auto import tqdm\n",
    "\n",
    "# sr = dnn_superres.DnnSuperResImpl_create()\n",
    "# fullModelName = 'LapSRN_x8.pb'\n",
    "# first_part = output_video.split('.')[1]\n",
    "# second_part = output_video.split('.')[2]\n",
    "# output_path = '.'+first_part+'_'+fullModelName.replace('.pb', '')+'.'+second_part\n",
    "# path = f\"./input/models/{fullModelName}\"\n",
    "# modelName = fullModelName.split(os.path.sep)[-1].split(\"_\")[0].lower()\n",
    "# modelScale = fullModelName.split(\"_x\")[-1]\n",
    "# modelScale = int(modelScale[:modelScale.find(\".\")])\n",
    "\n",
    "# vs = cv2.VideoCapture(input_video)\n",
    "# success, frame = vs.read()\n",
    "# input_width = frame.shape[1] # 640\n",
    "# input_height = frame.shape[0] # 352\n",
    "# frame_count = 0\n",
    "# total_frames = vs.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "# frame_rate = vs.get(cv2.CAP_PROP_FPS)\n",
    "# print(f'input res: {frame.shape}, total frames={total_frames}, frame rate={frame_rate},\\\n",
    "#        scale={modelScale}, outpath={output_path}')\n",
    "\n",
    "# sr.readModel(path)\n",
    "# sr.setModel(modelName, modelScale)\n",
    "\n",
    "# out = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'mp4v'),\n",
    "#                          frame_rate, (modelScale*input_width, modelScale*input_height))\n",
    "\n",
    "# with tqdm(total=total_frames) as pbar:\n",
    "#     while success:\n",
    "#         upsampled_frame = sr.upsample(frame)\n",
    "#         out.write(upsampled_frame)\n",
    "\n",
    "#         frame_count += 1\n",
    "#         pbar.update(1)\n",
    "#         pbar.set_description(f'frame no: {frame_count}')\n",
    "#         success, frame = vs.read() \n",
    "#         if frame_count > 150:\n",
    "#             break\n",
    "#     pbar.close()\n",
    "\n",
    "# vs.release()\n",
    "# out.release()\n",
    "# print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import os\n",
    "# from tqdm.auto import tqdm\n",
    "# from diffusers import LDMSuperResolutionPipeline, StableDiffusionUpscalePipeline\n",
    "# import torch\n",
    "# from PIL import Image\n",
    "\n",
    "# fullModelName = 'stabilityai-stable-diffusion-x4-upscaler' # 'CompVis-ldm-super-resolution-4x-openimages'\n",
    "# model_id = 'stabilityai/stable-diffusion-x4-upscaler'  # \"CompVis/ldm-super-resolution-4x-openimages\"\n",
    "# first_part = output_video.split('.')[1]\n",
    "# second_part = output_video.split('.')[2]\n",
    "# output_path = '.'+first_part+'_'+fullModelName.replace('.pb', '')+'.'+second_part\n",
    "\n",
    "# modelName = fullModelName  # .split(os.path.sep)[-1].split(\"_\")[0].lower()\n",
    "# modelScale = 4\n",
    "# # pipeline = LDMSuperResolutionPipeline.from_pretrained(model_id)\n",
    "# pipeline = StableDiffusionUpscalePipeline.from_pretrained(model_id, torch_dtype=torch.float16)\n",
    "# device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# pipeline = pipeline.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vs = cv2.VideoCapture(input_video)\n",
    "# success, frame = vs.read()\n",
    "# input_width = frame.shape[1] # 640\n",
    "# input_height = frame.shape[0] # 352\n",
    "# frame_count = 0\n",
    "# total_frames = vs.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "# frame_rate = vs.get(cv2.CAP_PROP_FPS)\n",
    "# print(f'input res: {frame.shape}, total frames={total_frames}, frame rate={frame_rate},\\\n",
    "#        scale={modelScale}, outpath={output_path}')\n",
    "\n",
    "# out = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'mp4v'),\n",
    "#                          frame_rate, (modelScale*input_width, modelScale*input_height))\n",
    "\n",
    "# with tqdm(total=total_frames) as pbar:\n",
    "#     while success:\n",
    "#         if frame_count == 100:\n",
    "#             srcImg = Image.fromarray(frame)\n",
    "\n",
    "#             tgtImg = pipeline(srcImg, num_inference_steps=50, eta=1).images[0]\n",
    "#             srcImg.show()\n",
    "#             tgtImg.show()\n",
    "#             break\n",
    "#         # upsampled_frame = pipeline(Image.fromarray(frame), num_inference_steps=100, eta=1).images[0]\n",
    "#         # out.write(np.array(upsampled_frame))\n",
    "#         frame_count += 1\n",
    "#         pbar.update(1)\n",
    "#         pbar.set_description(f'frame no: {frame_count}')\n",
    "#         success, frame = vs.read()\n",
    "#         # if frame_count > 150:\n",
    "#         #     break\n",
    "#     pbar.close()\n",
    "\n",
    "# vs.release()\n",
    "# out.release()\n",
    "# print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['output/videos/low_res_2/low_res_2_BSRGAN_0.mp4',\n",
       " 'output/videos/low_res_2/low_res_2_BSRGAN_1.mp4',\n",
       " 'output/videos/low_res_2/low_res_2_BSRGAN_2.mp4',\n",
       " 'output/videos/low_res_2/low_res_2_BSRGAN_3.mp4']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(map(lambda file: output_root_path+'/'+file, os.listdir(output_root_path)))\n",
    "\n",
    "from pathlib import Path\n",
    "paths = sorted(Path(output_root_path).iterdir(), key=os.path.getmtime)\n",
    "files_sorted = list(map(str, sorted(Path(output_root_path).iterdir(), key=os.path.getmtime)))\n",
    "files_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 3, 64, 23, 32, 4]\n",
      "input res: (240, 320, 3), total frames=913.0, frame rate=30.0, scale=4, outpath=./output/videos/low_res_2/low_res_2_BSRGAN_3.mp4, completed_frames=325.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e631a2983087448d8861c43a403b4a37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/913.0 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished 913.0 frames (100.0%)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "import torch\n",
    "from PIL import Image\n",
    "import time\n",
    "import sys\n",
    "sys.path.append(os.path.abspath('/home/asutosh/Documents/ml_projects/BSRGAN'))\n",
    "from models.network_rrdbnet import RRDBNet as net\n",
    "from utils import utils_image as util\n",
    "\n",
    "def get_output_file_path(file_name, model_name, file_part, parent_path, ext):\n",
    "    file_prefix = f'{file_name}_{model_name}_{file_part}'\n",
    "    output_path = f'{parent_path}/{file_prefix}.{ext}'\n",
    "    return output_path\n",
    "\n",
    "model_name = 'BSRGAN'\n",
    "file_part = len(os.listdir(output_root_path))\n",
    "output_part_path = get_output_file_path(file_name, model_name, file_part, output_root_path, ext)\n",
    "number_of_frames_completed = -1\n",
    "\n",
    "if file_part == 0:\n",
    "    number_of_frames_completed = 0\n",
    "else :\n",
    "    file_parts = os.listdir(output_root_path)\n",
    "    for file_part_ in file_parts:\n",
    "        vs = cv2.VideoCapture(f'{output_root_path}/{file_part_}')\n",
    "        number_of_frames_completed += vs.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "\n",
    "modelScale = 4\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model_path = f'./input/models/{model_name}.pth'\n",
    "time_limit = 6*60 # seconds\n",
    "start_time = time.time()\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "model = net(in_nc=3, out_nc=3, nf=64, nb=23, gc=32, sf=modelScale)  # define network\n",
    "model.load_state_dict(torch.load(model_path), strict=True)\n",
    "model.eval()\n",
    "for k, v in model.named_parameters():\n",
    "    v.requires_grad = False\n",
    "model = model.to(device)\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "vs = cv2.VideoCapture(input_video)\n",
    "vs.set(cv2.CAP_PROP_POS_FRAMES, number_of_frames_completed)\n",
    "success, frame = vs.read()\n",
    "input_width = frame.shape[1] # 640\n",
    "input_height = frame.shape[0] # 352\n",
    "frame_count = 0\n",
    "total_frames = vs.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "frame_rate = vs.get(cv2.CAP_PROP_FPS)\n",
    "out_resolution = (modelScale*input_width, modelScale*input_height)\n",
    "\n",
    "print(f'input res: {frame.shape}, total frames={total_frames}, frame rate={frame_rate}, scale={modelScale}, outpath={output_part_path}, completed_frames={number_of_frames_completed}')\n",
    "\n",
    "codec = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out = cv2.VideoWriter(output_part_path, codec,\n",
    "                         frame_rate, out_resolution)\n",
    "\n",
    "with tqdm(total=total_frames) as pbar:\n",
    "    pbar.update(number_of_frames_completed)\n",
    "    frame_count = number_of_frames_completed\n",
    "    while success:\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        frame = util.uint2tensor4(frame).to(device)\n",
    "        upsampled_frame = model(frame)\n",
    "        upsampled_frame = util.tensor2uint(upsampled_frame)\n",
    "        upsampled_frame = cv2.cvtColor(upsampled_frame, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        out.write(upsampled_frame)\n",
    "        frame_count += 1\n",
    "        pbar.update(1)\n",
    "        pbar.set_description(f'frame no: {frame_count}')\n",
    "        success, frame = vs.read()\n",
    "        if frame_count % 50:\n",
    "            # check if run time > time_limit\n",
    "            if time.time() - start_time > time_limit:\n",
    "                break\n",
    "            \n",
    "    pbar.close()\n",
    "\n",
    "vs.release()\n",
    "out.release()\n",
    "print(f'finished {frame_count} frames ({frame_count/total_frames*100}%)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3b146bf55d04ef2855233e3109f633f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "video combined at ./output/videos/low_res_2/low_res_2_BSRGAN_all.mp4\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "def concatenate_videos(new_video_path, codec, fps, resolution, videos):\n",
    "    video = cv2.VideoWriter(new_video_path, codec, fps, resolution)\n",
    "\n",
    "    for v in tqdm(videos):\n",
    "        curr_v = cv2.VideoCapture(v)\n",
    "        while curr_v.isOpened():\n",
    "            r, frame = curr_v.read()\n",
    "            if not r:\n",
    "                break\n",
    "            video.write(frame)\n",
    "\n",
    "    video.release()\n",
    "    print(f'video combined at {new_video_path}')\n",
    "\n",
    "files_sorted = list(map(str, sorted(Path(output_root_path).iterdir(), key=os.path.getmtime)))\n",
    "concat_path = get_output_file_path(file_name, model_name, 'all', output_root_path, ext)\n",
    "concatenate_videos(concat_path, codec, frame_rate, out_resolution, files_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video ./output/videos/low_res_2/low_res_2_BSRGAN_final.mp4.\n",
      "MoviePy - Writing audio in low_res_2_BSRGAN_finalTEMP_MPY_wvf_snd.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video ./output/videos/low_res_2/low_res_2_BSRGAN_final.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready ./output/videos/low_res_2/low_res_2_BSRGAN_final.mp4\n"
     ]
    }
   ],
   "source": [
    "video_out = moviepy.editor.VideoFileClip(concat_path)\n",
    "audio = audio.volumex(2)\n",
    "video_with_audio = video_out.set_audio(audio)\n",
    "output_video_audio = get_output_file_path(file_name, model_name, 'final', output_root_path, ext)\n",
    "video_with_audio.write_videofile(output_video_audio)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
